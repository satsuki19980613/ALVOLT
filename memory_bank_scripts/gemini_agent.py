import os
import time
import oracledb
import google.generativeai as genai
from dotenv import load_dotenv
import array
import sys

# æ–‡å­—åŒ–ã‘å¯¾ç­–
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

load_dotenv()

# --- è¨­å®š ---
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
EMBEDDING_MODEL = "models/text-embedding-004"
# ãƒ¢ãƒ‡ãƒ«åã¯ã”è‡ªèº«ã®ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ï¼ˆgemini-1.5-flash-001 ãªã©ï¼‰
CHAT_MODEL = "models/gemini-2.0-flash-001"

def get_db_connection():
    return oracledb.connect(
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        dsn=os.getenv("DB_DSN"),
        config_dir=os.getenv("WALLET_DIR"),
        wallet_location=os.getenv("WALLET_DIR"),
        wallet_password=os.getenv("DB_PASSWORD")
    )

def get_embedding(text):
    try:
        time.sleep(1) # APIåˆ¶é™å›é¿
        res = genai.embed_content(model=EMBEDDING_MODEL, content=text)
        return res['embedding']
    except: return None

# --- ğŸ’¾ ãƒ¡ãƒ¢ãƒªæ“ä½œæ©Ÿèƒ½ ---

def save_episode(role, text):
    """ä¼šè©±ã‚’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã¨ã—ã¦DBã«ä¿å­˜"""
    vector = get_embedding(text)
    if not vector: return

    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO episodic_memory (role, content, content_embedding)
            VALUES (:1, :2, :3)
        """, [role, text, array.array('f', vector)])
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"Error saving episode: {e}")

def recall_past_episodes(query):
    """ç¾åœ¨ã®ä¼šè©±ã«é–¢é€£ã™ã‚‹éå»ã®ä¼šè©±(ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰)ã‚’æ€ã„å‡ºã™"""
    vector = get_embedding(query)
    if not vector: return ""

    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        sql = """
            SELECT role, content, created_at,
                   VECTOR_DISTANCE(content_embedding, :1, COSINE) as distance
            FROM episodic_memory
            ORDER BY distance ASC
            FETCH FIRST 5 ROWS ONLY
        """
        cursor.execute(sql, [array.array('f', vector)])
        results = cursor.fetchall()

        if not results: 
            conn.close()
            return ""
        
        # ã€ä¿®æ­£ã€‘æ¥ç¶šãŒç”Ÿãã¦ã„ã‚‹é–“ã«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚‹
        memory_text = "\n=== ğŸ•°ï¸ Past Related Conversations (Episodic Memory) ===\n"
        for row in results:
            role = row[0]
            # LOBã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿å‡ºã™
            content = row[1].read() 
            memory_text += f"- [{role}]: {content[:200]}...\n"
        
        conn.close()
        memory_text += "=====================================================\n"
        return memory_text

    except Exception as e:
        return f"Memory Recall Error: {e}"

# --- ğŸ› ï¸ æ—¢å­˜ãƒ„ãƒ¼ãƒ« (ã‚³ãƒ¼ãƒ‰æ¤œç´¢) ---

def search_codebase_semantic(query: str):
    """ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ„å‘³æ¤œç´¢ï¼ˆSemantic Memoryï¼‰"""
    time.sleep(2)
    print(f"\n[System] ğŸ” Searching Semantic Memory for: '{query}'...")
    
    vector = get_embedding(query)
    if not vector: return "Error"
    
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        sql = """
            SELECT file_path, VECTOR_DISTANCE(content_embedding, :1, COSINE) as dist
            FROM project_artifacts ORDER BY dist ASC FETCH FIRST 5 ROWS ONLY
        """
        cursor.execute(sql, [array.array('f', vector)])
        results = cursor.fetchall()
        conn.close()
        
        if not results: return "No files found."
        return "\n".join([f"- {r[0]}" for r in results])
    except Exception as e:
        return f"Database Error: {e}"

def read_file_content(file_path: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’èª­ã‚€"""
    time.sleep(2)
    print(f"\n[System] ğŸ“– Reading file: '{file_path}'...")
    
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("SELECT file_path, content FROM project_artifacts WHERE file_path LIKE :1 FETCH FIRST 1 ROWS ONLY", [f"%{file_path}%"])
        row = cursor.fetchone()
        
        if not row: 
            conn.close()
            return "File not found."
        
        # ã€ä¿®æ­£ã€‘ã“ã“ã‚‚æ¥ç¶šãŒç”Ÿãã¦ã„ã‚‹é–“ã«èª­ã¿å–ã‚‹
        real_path = row[0]
        file_content = row[1].read()
        
        conn.close()
        return f"=== FILE: {real_path} ===\n{file_content}\n"
    except Exception as e:
        return f"Database Error: {e}"

# --- ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœ¬ä½“ ---

tools = [search_codebase_semantic, read_file_content]

system_instruction = """
ã‚ãªãŸã¯ALVOLTãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã€Œ2ã¤ã®è¨˜æ†¶ã€ã‚’é§†ä½¿ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

1. **Semantic Memory (ã‚³ãƒ¼ãƒ‰æ¤œç´¢)**: ã‚³ãƒ¼ãƒ‰ã®ä»•æ§˜ã‚„å®Ÿè£…è©³ç´°ãŒå¿…è¦ãªå ´åˆã«ä½¿ç”¨ã€‚
2. **Episodic Memory (ä¼šè©±å±¥æ­´)**: è‡ªå‹•çš„ã«æä¾›ã•ã‚Œã¾ã™ã€‚éå»ã®çµŒç·¯ã‚’è¸ã¾ãˆã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

å¸¸ã«æ—¥æœ¬èªã§å›ç­”ã—ã€ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãŒå¿…è¦ãªå ´åˆã¯å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
"""

model = genai.GenerativeModel(
    model_name=CHAT_MODEL,
    tools=tools,
    system_instruction=system_instruction
)

chat = model.start_chat(enable_automatic_function_calling=True)

print("ğŸ¤– ALVOLT Agent with Memory Engineering (Ready)")
print("-------------------------------------------------")

while True:
    try:
        user_input = input("\nYou: ")
        if user_input.lower() in ["exit", "quit"]: break

        save_episode('user', user_input)
        
        past_memories = recall_past_episodes(user_input)
        full_prompt = f"{past_memories}\nUser Query: {user_input}"
        
        response = chat.send_message(full_prompt)
        print(f"Gemini: {response.text}")

        save_episode('assistant', response.text)

    except Exception as e:
        print(f"Error: {e}")